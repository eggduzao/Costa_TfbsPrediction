\chapter{Results}
\label{chapter_results}
We first describe the results of experiments performed without replicates, where we evaluate our algorithm ODIN.
Second, we explain the results of experiments that contain replicates.
Here, we investigate the performance of THOR.

\section{Experiments with ODIN}
We describe the results of experiments with ODIN.
First, we describe the findings of the simulated ChIP-seq data without replicates.
We then give the results for the biological data without replicates evaluated with the DAGE statistic.

\subsection{Experiments with Simulated Data}
As described in Section~\ref{sec_expmethods_sim_without} we investigate the effect of variable size in the protein domains as well as a variable number of reads in the ChIP-seq experiments.
Figure~\ref{fig_results_sim_without_rep} shows the results for simulated data without replicates. 
As expected, methods perform best for experiments with more reads and less number of proteins per domain (bottom left). 
The reason is that less number of proteins per domain shape isolated peaks in the signal.
In combination with a high number of reads per protein, these peaks additionally are well-defined.
As a consequence, this scenario presents an easy differential peak calling problem.
The performance of MAnorm for top ranked DPs is quite competitive with ODIN variants for data with few proteins per domains (left column), but its performance deteriorates whenever more proteins are present in the domains. 
MACS2 has similar performance as ODIN variants when large number of reads are present (bottom), but ODIN clearly outperforms MAC2 when peak sizes have a high variance (middle row). 
We calculate the Area Under the Curve (AUC) for each experiment to perform the Friedman-Nemenyi test.
We then evaluate the overall performance of methods for all conditions (see Table~\ref{tab_sim_ranking_sig_without_rep} and Sup.~Table~\ref{tab_sim_ranking_without_rep} for the Friedman ranking). 
Results indicates that ODIN with  Binomial or single Poisson distribution has a significantly higher AUC scores than MACS2, MAnorm, DESeq-MACS and DBChIP ($p$-value $< 0.1$).
Other tools do not significantly outperform any other tool.

\begin{table}[th]
\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
  \begin{tabular}{ rccccccccc }
    & \rotatebox{90}{ODIN-Binomial} & \rotatebox{90}{ODIN-Poisson-1} & \rotatebox{90}{ODIN-Poisson-4} & \rotatebox{90}{ODIN-Poisson-3} & \rotatebox{90}{ODIN-Poisson-2} & \rotatebox{90}{MACS2} & \rotatebox{90}{MAnorm} & \rotatebox{90}{DESeq-MACS} & \rotatebox{90}{DBChIP} \\
    \hline
    ODIN-Binomial &     &     &     &     &     &     &     &     &     \\
    ODIN-Poisson-1 &     &     &     &     &     &     &     &     &     \\
    ODIN-Poisson-4 &     &     &     &     &     &     &     &     &     \\
    ODIN-Poisson-3 &     &     &     &     &     &     &     &     &     \\
    ODIN-Poisson-2 & $+$ &     &     &     &     &     &     &     &     \\
    MACS2 & $*$ & $+$ &     &     &     &     &     &     &     \\
    MAnorm & $*$ & $+$ &     &     &     &     &     &     &     \\
    DESeq-MACS & $*$ & $*$ & $*$ & $+$ &     &     &     &     &     \\
    DBChIP & $*$ & $*$ & $*$ & $*$ &     &     &     &     &     \\
    \hline
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of simulated data without replicates]{Results for the simulated datasets without replicates. 
The table is based on the Friedman-Nemenyi hypothesis test and the AUC scores. The asterisk and the cross, respectively, mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1.}
\label{tab_sim_ranking_sig_without_rep}
\end{table}

\begin{figure}[ht]
  \centering
   \includegraphics[width=14.3cm]{pics/res_sim_without_rep}
\caption[Simulation results without replicates]{Average ratio of true positive DPs for all compared methods over nine distinct parameters of the simulated data. 
The number of reads per peak increases from top to bottom.
The number and variance of proteins within a domain increases from left to right.}
\label{fig_results_sim_without_rep}
\end{figure}

\subsection{Experiments with Biological Data}
First, we evaluate the impact of the preprocessing steps performed to create and improve the ChIP-seq signal (see Section~\ref{sec_prepocessing_pipeline}).
Second, we evaluate different parametrizations of our algorithm ODIN.
Next, we compare ODIN's $p$-value estimation (see Section~\ref{sec_pvalue}) with the strategy from DESeq and edgeR.
For these parametrization experiments we restrict our analysis to chromosome~1.
We discard chromosome~1 for the further analysis with biological real data sets.
Finally, we describe the DAGE results for ODIN, MANorm, DeSeq, MACS2 and ChIPDiff (see Table~\ref{tab_tools}) based on all biological datasets without replicates (see Table~\ref{table_datasets_without_replicates}).

\subsubsection{Genomic Signal Construction}
We investigate the effect of the preprocessing steps to create the genomic signal (see Section~\ref{sec_prepocessing_pipeline}).
In particular, we analyse all 8 combinations of using: (1) the \nuc{GC}-content model, (2) filtering reads aligned to poor mappability regions and (3) the subtraction of input-DNA. 
The Friedman-Nemenyi test on DAGE statistics ($h=50,\ H=500$) indicates a slight advantage of using input-DNA subtraction and \nuc{GC}-content model compared to using none of the steps for TF data ($p\text{-value} < 0.1$). 
No significant difference is detected on histone data. 
However, the Friedman score ranks are similar in both scenarios reinforcing the advantage of the input-DNA subtraction and \nuc{GC}-content model, which will be further used in all experiments (see Sup.~Table~\ref{tab_preprocess_tf} -- Sup.~Table~\ref{tab_preprocess_hist_sig}).



\subsubsection{Method Parametrization}
We evaluate the use of parameter constraints and the choice of the HMM's emission distribution as presented in Section~\ref{sec_hmm_training}. 
We compute the DAGE statistic ($h=50,\ H=500$) with or without parameter constraints.

First, the constrained model has statistical significant higher DAGE values ($p\text{-value} < 0.006$, one-tailed Wilcoxon test) for experiments with TFs, while no significant differences are obtained for histone modification experiments. 
This reinforces the advantage of parameter constraints, which is used in further experiments.

Furthermore, we evaluate the use of distinct emission distributions for ODIN: Binomial and mixture of Poisson with 1 to 4 components. 
As shown in Sup. Table~\ref{tab_preprocess_dist_tf} -- Sup. Table~\ref{tab_preprocess_dist_sig}, no significant difference was found. 
We therefore use the Poisson mixture with the number of components that offers the highest ranking (4 for histones and 1 TFs) as well as the Binomial distribution in the following experiments. 

Finally, we inspect the impact of SPCs (MACS, QUEST and PeakSeq) on two-stage DPCs DPChIP, DESeq and MAnorm. 
As shown in Sup. Table~\ref{tab_preprocess_spc_tf} -- Sup. Table~\ref{tab_preprocess_spc_hist_sig}, no significant difference between the used SPCs was found. 
We therefore use the best ranked combination for the follow-up experiments: MAnorm-macs, DESeq-quest and DBChIP-quest. 


\subsubsection{Evaluation $P$-value Estimation Strategies}
We evaluate the $p$-value estimation methods of ODIN, DESeq~\citep{anders2010} and EdgeR~\citep{robinson2010}.
We use DPs predicted by ODIN with a Binomial distribution for all 15 datasets. 
ODIN's $p$-value estimation leads to a significant higher DAGE score than the $p$-value estimation of DESeq and EdgeR for TF experiments and a significant higher DAGE score than EdgeR for histone experiments (see Table~\ref{tab_pvaluecomp_tf_hist_sig}; Sup. Table~\ref{tab_pvaluecomp_tf} and Sup. Table~\ref{tab_pvaluecomp_hist} give the Friedman rankings for the experiments).

\begin{table}[h!]
\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
  \begin{tabular}{ r | ccc | ccc}
    & \multicolumn{3}{c|}{TF} & \multicolumn{3}{c}{histone mod.} \\
    & \rotatebox{90}{ODIN} & \rotatebox{90}{ODIN-DESeq} & \rotatebox{90}{ODIN-edgeR} & \rotatebox{90}{ODIN} & \rotatebox{90}{ODIN-DESeq} & \rotatebox{90}{ODIN-edgeR}\\
    \hline
    ODIN &     &     &     &     &     &\\
    ODIN-DESeq & $*$ &     &     &     &     &\\
    ODIN-edgeR & $*$ &     &     & $*$ & $*$ &\\
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of $p$-value estimation strategies]{$P$-value estimation evaluation based on histone modification and TF experiments.
We estimate $p$-values with our strategy (ODIN, see Section~\ref{sec_pvalue}), the strategy of DESeq (ODIN-DESeq) and the strategy of edgeR (ODIN-edgeR) for histone modification and TF experiments.
The asterisk and the cross, respectively, mean that the method in the column outperformed the method with regard to the DAGE scores in the row with significance levels of 0.05 and 0.1.}
\label{tab_pvaluecomp_tf_hist_sig}
\end{table}

\subsubsection{Comparative Evaluation on Biological Data}
In Figure~\ref{fig_results_without_rep_dage} we display DAGE curves for DBChIP, MACS2, our DESeq approach, MAnorm and ODIN for four selected experiments on real data. 
As ChIPDiff does not provide information to sort the DPs, its results are only represented as points, where the $x$-axis location corresponds to the number of called DPs. 
In most scenarios, curves approximate to zero for higher ranks, which indicates that higher ranked DPs are associated to higher expression changes. 
In some scenarios, such as TLR4-H3K4me2-0h-6h, the curve associated with {\tt Gain 2} DPs (Figure~\ref{fig_results_without_rep_dage}H) are further from 0 than {\tt Gain 1} DPs (Figure~\ref{fig_results_without_rep_dage}G). 
This is an indication that there are more changes in ChIP-seq peaks and gene expression in signal 2 (6h) than in signal 1 (0h). 
This is in accordance with the main message of the TLR4 study, which shows that induction of TLR4 promotes new enhancers marked by H3K4me2~\citep{kaikonnen2013}. 
While there are some experiment specific variations, both ODIN variants outperform other methods on DC-PU.1-MPP-CDP (Figure~\ref{fig_results_without_rep_dage}A, B), DC-H3K4me1-MPP-CDP (Figure~\ref{fig_results_without_rep_dage}C, D).
Furthermore, the performance of ODIN with Binomial distribution is similar to other methods on TRL4-H3K4me1-0h-6h (Figure~\ref{fig_results_without_rep_dage}G, H) and TRL4-PU.1-0h-6h (Figure~\ref{fig_results_without_rep_dage}E, F).
All DAGE curves can be found at Sup. Figure~\ref{fig_dage1} -- Sup. Figure~\ref{fig_dage4}.

\begin{figure*}[ht]
%   \hspace{2cm}
  \begin{center}
  \centering
   \includegraphics[width=\textwidth]{pics/res_evaluation_without_rep}
  \end{center}
\caption[Selection of DAGE curves]{Here we depict the DAGE curves for selected experiments from TLR4 and DC studies. 
Lines in the first and third row represent DP gained in the first signal (\hmmstate{Gain~1}), while lines in the second and fourth row in the second signal (\hmmstate{Gain~2}). 
}
\label{fig_results_without_rep_dage}
\end{figure*}


Moreover, we evaluate the performance of all methods for all 15 real data experiments  listed in Table \ref{table_datasets_without_replicates}  by computing the DAGE scores for \hmmstate{Gain~1} and \hmmstate{Gain~2} peaks. 
The Friedman-Nemenyi test indicates that both ODIN variants have significantly higher DAGE scores than DBChIP and MACS2 on TF experiments ($p\text{-value} < 0.1$, see Table~\ref{tab_dage_tf_sig}, Sup. Table~\ref{tab_dage_tf} gives the Friedman ranking) and significantly higher DAGE scores than DESeq on histone data ($p\text{-value}~<~0.05$, see Table~\ref{tab_dage_hist_sig}, Sup. Table~\ref{tab_dage_hist} gives the Friedman ranking). 
Moreover, ODIN with Binomial distribution has a significant higher DAGE score than MACS2 and MAnorm on histone and TF data. 

\begin{table}[h!]
\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
  \begin{tabular}{ rccccc }
    & \rotatebox{90}{ODIN-poisson-1} & \rotatebox{90}{ODIN-binomial} & \rotatebox{90}{MAnorm-macs} & \rotatebox{90}{MACS2} & \rotatebox{90}{DBChIP-quest} \\
    \hline
    ODIN-poisson-1 &     &     &     &     &     \\
    ODIN-binomial &     &     &     &     &     \\
    MAnorm-macs & $*$ &     &     &     &     \\
    MACS2 & $*$ & $+$ &     &     &     \\
    DBChIP-quest & $*$ & $*$ &     &     &     \\
    \hline
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of DAGE results for TF experiments]{DAGE results based on TF experiments. Friedman-Nemenyi hypothesis test results for the \textbf{AUC} metric. The asterisk and the cross, respectively, mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1.}
\label{tab_dage_tf_sig}

\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
  \begin{tabular}{ rccccc }
    & \rotatebox{90}{ODIN-binomial} & \rotatebox{90}{ODIN-poisson-4} & \rotatebox{90}{MAnorm-macs} & \rotatebox{90}{MACS2} & \rotatebox{90}{DEseq-quest} \\
    \hline
    ODIN-binomial &     &     &     &     &     \\
    ODIN-poisson-4 &     &     &     &     &     \\
    MAnorm-macs & $*$ &     &     &     &     \\
    MACS2 & $*$ &     &     &     &     \\
    DEseq-quest & $*$ & $*$ &     &     &     \\
    \hline
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of DAGE results for histone experiments]{DAGE results based on histone experiments. Friedman-Nemenyi hypothesis test results for the \textbf{AUC} metric. The asterisk and the cross, respectively, mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1.}
\label{tab_dage_hist_sig}
\end{table}

We also performed an evaluation of ChIPDiff by comparing the DAGE values of all methods with $H$ equal to the number of peaks called by ChIPDiff. 
ODIN with Binomial distribution has significantly higher DAGE scores than ChIPDiff on TF experiments ($p\text{-value}~<~0.1$, see Sup. Table~\ref{tab_dagechipdiff_tf} and Sup. Table~\ref{tab_dagechipdiff_tf_sig}), while no statistical difference was detected on histone data (see Sup. Table~\ref{tab_dagechipdiff_hist} and Sup. Table~\ref{tab_dagechipdiff_hist_sig}). 
In all cases, both ODIN with Binomial and mixture of Poisson distribution ranked best by the Friedman score compared to all competing methods.

We perform a visual inspection of the DPs from experiment TLR4-H3K4me2-0h-24h around gene Irf1.
In Figure~\ref{fig_results_without_rep_example_ext} we show the DP estimates for the same genomic region already shown in Figure~\ref{pic_dp_example}. 
MAnorm and our approach DESeq-quest can successfully detect changes in large peak areas. 
ChIPDiff detects most DPs, but have a tendency to call large regions. 
ODIN and MACS2 are able to detect detailed changes within the large domains. 
MACS2 and ChIPDiff are not able to recover a DP upstream of Irf1 (marked as DP2) in H3K4me2 0h. 
The loss of this histone mark after TLR4 treatment is supported by gain of PU.1 on the very sample location for PU.1 ChIP-seq profiles.

\begin{figure}[ht]
  \centering
   \includegraphics[width=13cm]{pics/res_without_rep_example_ext}
\caption[Example of DPs in biological data without replicates]{DPs detected on experiment TLR4-H3K4me2-0h-24h around the Irf1 gene. Bars bellow the ChIP-seq signal indicate the regions called as DPs by distinct methods.}
\label{fig_results_without_rep_example_ext}
\end{figure}

\clearpage


\section{Experiments with THOR}
We describe the results of experiments with THOR and its competing methods. 
First, we describe the findings of the simulated ChIP-seq data with replicates. 
Next, we detail the results for the biological data with replicates which we evaluate with the DCA statistic.

\subsection{Experiments with Simulated Data}
Figure~\ref{pic_res_sim_with} shows the distributions of AUC values for all methods and experimental combinations. 
The first simulation parameter is the number of replicates (red vs. green lines). 
We observe that most methods have lower AUC values in experiments with 2 replicates (red line) then with 4 replicates (green line) (p-value < 0.05; one-sided Wilcoxon test). 
Exceptions are Poisson-THOR and IDR. 
IDR returns very few peaks on cases with 4 replicates (green line), even when using an lenient threshold the SPC used as input for IDR. 
Poisson-THOR's poor performance on 4 replicates possibly stems from its simple distribution, which does not cope with overdispersion.

\begin{figure}[h]
 \begin{center}
  \includegraphics[width=\textwidth]{pics/res_sim_withrep_boxplots.pdf}
 \end{center}
 \caption[Simulation results with replicates]{Results for simulated data with replicates. 
 We show the AUC distribution for 25 repetitions of each scenario. 
 Simulated data were based on moderate (A) and high (B) condition peak size variability and 2 (red lines) and 4 (green lines) replicates. 
 Each boxplot is divided by the level of within condition variance (low, medium and high). 
 Methods (x-axis) are ordered by decreasing median AUC values (y-axis) for the cases with 4 replicates.
}
 \label{pic_res_sim_with}
\end{figure}

The second simulation parameter is the variance of the peak sizes, where we evaluate scenarios with moderate (Figure~\ref{pic_res_sim_with}A) and high (Figure~\ref{pic_res_sim_with}B) variance. 
Two methods have higher AUC values in scenarios with moderate peak variance. 
THOR in case of low and medium within variance and 2 replicates ($p$-value $< 10^{-4}$, one-sided Wilcoxon test), as well as DiffBind in the case with low, medium and high within variance and 2 replicates ($p$-value $< 4.7 \cdot 10^{-8}$, one-sided Wilcoxon test). 
All other methods show no significant changes in AUC values. 

The third characteristic is the level of variance within the replicates. 
DESeq-JAMM, Diff\-Re\-ps and DESeq-IDR show decrease in AUC values for increasing variance. 
Interestingly, the performance of THOR, MACS2 and DiffBind shows increase in AUC values with increasing variance for respectively 5, 3 and 6 of the eight cases ($p$-value $< 0.05$; one-sided Wilcoxon test).

Finally, we apply the Friedman-Neymeni test for all data together to evaluate the statistical significance in AUC value differences for distinct methods. 
THOR has significantly higher AUC scores than all competing methods. 
MACS2 has significant higher AUC values than DiffReps, DESeq-IDR, DiffBind and Poisson-THOR; and DESeq-JAMM and DiffReps have significantly higher AUC values than DiffBind and Poisson-THOR ($p$-value $< 0.05$, see Table~\ref{tab_res_with_rep_sim_all_sig} and Sup. Table~\ref{tab_res_with_rep_sim_all} for the Friedman ranking). 
Evaluating specific conditions, THOR has significantly higher AUC values than DiffReps, DiffBind and Poisson-THOR for all 12 cases ($p$-value $< 0.05$, Sup. Table~\ref{res_with_sep_cond_low_mod_2rep} -- Sup. Table~\ref{res_with_sep_cond_high_high_4rep}).
In the case with 2 replicates, THOR additionally has significantly higher AUC values than DESeq-JAMM ($p$-value $< 0.05$, Sup. Table~\ref{res_with_sep_cond_low_mod_2rep} -- Sup. Table~\ref{res_with_sep_cond_high_high_2rep}) and in the case with 4 replicates significantly higher AUC values than DESeq-IDR ($p$-value $< 0.05$, Sup. Table~\ref{res_with_sep_cond_low_mod_4rep} -- Sup. Table~\ref{res_with_sep_cond_high_high_4rep}). 
THOR is ranked top in all of the 12 cases.

\begin{table}[h!]
\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
  \begin{tabular}{ rccccccc }
    & \rotatebox{90}{THOR} & \rotatebox{90}{MACS2} & \rotatebox{90}{DESeq-JAMM} & \rotatebox{90}{DiffReps} & \rotatebox{90}{DESeq-IDR} & \rotatebox{90}{DiffBind} & \rotatebox{90}{Poisson-THOR} \\
    \hline
    THOR &     &     &     &     &     &     &     \\
    MACS2 & $*$ &     &     &     &     &     &     \\
    DESeq-JAMM & $*$ & $+$ &     &     &     &     &     \\
    DiffReps & $*$ & $*$ &     &     &     &     &     \\
    DESeq-IDR & $*$ & $*$ &     &     &     &     &     \\
    DiffBind & $*$ & $*$ & $*$ & $*$ &     &     &     \\
    Poisson-THOR & $*$ & $*$ & $*$ & $*$ & $*$ & $*$ &     \\
    \hline
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of simulated data with replicates]{Friedman-Nemenyi test results based on the AUC statistic of simulated data for all scenarios. The asterisk and the cross, respectively, mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1.}
\label{tab_res_with_rep_sim_all_sig}
\end{table}


% \begin{itemize}
%  \item the same like the case without replicates
%  \item explain which parameters we want to investigate
%  \item tools: macs, THOR, diffbind, diffreps, csaw, DESeq-IDR, DESeq-JAMM
%  \item give results for simulation without replicates
%  \item show evaluation pictures and tables of Friedman Ranking
%  \item discuss results: advantages and disadvantages of tool in particular parameter settings
% \end{itemize}

% \subsection{Empirical Evaluation}
% \subsubsection{Data}
% \begin{itemize}
%  \item describe data that we have used: 1) Oltz: cancer dataset, Blueprint: macrophages to monocytes development, Nestler: cocaine mouse study, in-house study: dendritic cell development
%  \item gene expression data: microarray data for Oltz, RNA-seq for all others
%  \item give table with names for each dataset to refer to them easily, also give number of replicates, and kind of replicates (techn. and biol.)
%  \item give table with quality metrics (Landt) for data: \#reads/NRF, FRiP, NSC, RSC 
% \end{itemize}

% \subsubsection{Competing Methods and Parametrization}
% \begin{itemize}
%  \item refer to 'related work' from 'background', there all tools that deal not with replicates are already described: macs2, THOR, diffbind, diffreps, csaw, DESeq, pepr
%  \item describe the parametrization of competing tools
%  \item our tool THOR is applied to data, describe its parametrization 
% \end{itemize}

\subsection{Experiments with Biological Data}
First, we evaluate the impact of the initial DP estimates to train THOR's HMM. 
Second, we perform a quality analysis on the biological data sets used for the experiment (see Table~\ref{table_datasets_with_replicates}). 
Third, we evaluate THOR and its competing methods with the DCA statistic.
Next, we analyse the effect of overdispersion to the DPCs.
Finally, we describe use cases for THOR.
% We use DPs called by THOR to detect regulatory single nucleotide polymorphisms (rSNPs).
% Further, we apply THOR 
% XXX


\subsubsection{Initial DP Estimation}
According to our parametrization (see Section~\ref{sec_expmethods_with_biol_para}), the initial DPs we use to train THOR's HMM are based on a fold change $t_1$ and a minimum difference between signals~$t_2$.
We set the minimum signal support $t_3=t_1/2$.
We evaluated different parameter settings for $t_2 \in \{1.3, 1.6\}$ and $t_1 \in \big\{\langle x \rangle^{.95}, \langle x \rangle^{.99}\big\}$ by predicting DPs for chromosome 1 for all $12$ experiments with replicates. 
The Friedman-Nemenyi test on DCA statistics for $h = 100 $ and $H = 1000$ shows no statistical significant differences, which indicates that THOR is robust against distinct initial parameter setups~(see~Sup. Table~\ref{tab_dca_initial} and Sup. Table~\ref{tab_dca_initial_sig}). 
We used the parametrization with the highest ranking ($t_1 = 1.6,\ t_2 = \langle x \rangle^{.95}$) for all further experiments. 
Chromosome 1 was left out of the comparative method analysis. 

\subsubsection{Quality Analysis on Biological Data Sets}
To better understand the characteristics of ChIP-seq experiments evaluated in our study, we first perform a quality check. 
For this we use the FRiP (fractions of reads in peaks) score from the ENCODE consortia~\citep{landt2012} which gives an estimate of the signal-to-noise ratio of ChIP-seq experiments (see Section~\ref{sec_eval_chipseq_exp}). 
We also propose the use of the quadratic coefficient, that is, the variable $c_{1G_k}$ in Equation~\ref{eq_quad_func} which describes the mean-variance function, for a given biological condition as an indicator for ``overdispersion''. 
Figure~\ref{fig_quality_check}A and B give two examples of the mean-variance function of selected experiments.
Overdispersion positively correlates with the number of replicates in the condition (R=0.74, adjusted $p$-value=0.0001; Spearman Correlation). 
Moreover, higher overdispersion is associated to lower FRiP scores (R=-0.78; adjusted $p$-value=$2.9 \cdot 10^{-5}$). 
As depicted in Figure~\ref{fig_quality_check}C, average FRiP vs. overdispersion space separates the experiments by their expected complexity. 
The dendritic cell (DC) differentiation experiments, which were obtained by in vitro differentiation of cells with technical replicates, have highest FRiP values and lowest overdispersion values. 
The follicular lymphoma experiments (LYMP), which arise from patients with distinct genetic background and with potential tissue heterogeneity, have both highest overdispersion scores and lowest average FRiP. 
This indicates that the experiments evaluated here cover a large spectrum of peak size variance within biological conditions.

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=1.\textwidth]{pics/res_overdisp_FRiP.pdf}
  \end{center}
\caption[Mean-variance function examples and FRiP-overdispersion Association]{\textbf{(A)} and \textbf{(B)} Two examples for the mean-variance function described by Equation~\ref{eq_quad_func}. A high value (A) of $c_{1G_k}$ gives the function a quadratic and a low value (B) a linear shape. 
\textbf{(C)}~Association between average FRiP and overdispersion scores. 
FRiP and overdispersion scores for the 24 biological conditions analyzed: cocaine intake (CO), monocyte differentiation (MM), lymphoid cancer (LYMPH) and dendritic cell differentiation (DC). 
Higher FRiP indicates higher signal-to-noise ratio and better ChIP-seq experiments. 
Higher overdispersion scores indicates higher within condition variability. 
Arrows indicate the experiments described in (A) and (B).
}
\label{fig_quality_check}
\end{figure}

\subsubsection{Comparative Analysis of Biological Data}
We evaluate THOR and six competing methods (csaw, MACS2, DiffReps, PePr, DiffBind and DeSeq-IDR) on 12 differential peak calling problems using data from the cocaine intake on mice (CO), dendritic cell differentiation (DC), B cell follicular lymphoma (LYMP) and monocyte differentiation (MM) study (see Section~\ref{sec_biol_datasets} and Table~\ref{table_datasets_with_replicates})\footnote{We were not able to execute JAMM on these data sets, which was therefore left out of this analysis.}. 
We also evaluate the application of THOR with either the TMM (THOR-TMM) or the housekeeping genes (THOR-HK) normalization approach (see Section~\ref{sec_sample_norm}).
The performance of the methods was evaluated with the DCA (Differential Correlation Analysis) statistic. 
Figure~\ref{fig_res_real_datasets_with_rep} shows selected examples for DCA curves.
Sup. Figure~\ref{fig_dca_curves_co} -- Sup. Figure~\ref{fig_dca_curves_mm} give all 12 DCA curves.

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=\textwidth]{pics/res_merged_real_with_rep}
  \end{center}
\caption[Selection of DCA curves]{DCA curves for four selected DPCPs. 
We show DCA curves for (A) CO-H3K4me1, (B) DC-H3K27ac-CDP-cDC, (C) MM-H3K4me1 and (D) LYMP-FL-CC. 
Higher DCA values indicate higher association between differential peaks and differential expression.}
\label{fig_res_real_datasets_with_rep}
\end{figure}

We use the Friedman-Nemenyi test to check for significant differences in the area under the DCA curves (see Section~\ref{sec_friedman_test}).
THOR with both normalization strategies is the best ranked method and has significantly higher DCA values than DESeqIDR, csaw and Diffbind (adjusted $p$-value$<$0.05, Table~\ref{tab_res_real_with_rep_without_pepr_sig} and Sup. Table~\ref{tab_res_real_with_rep_without_pepr} for the Friedman ranking).
MACS2 also has significant higher DCA values than csaw (adjusted $p$-value$<$0.05).

\begin{table}[h!]
\begin{center}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{ rcccccccc }
    & \rotatebox{90}{THOR-HK} & \rotatebox{90}{THOR-TMM} & \rotatebox{90}{macs2} & \rotatebox{90}{DiffReps} & \rotatebox{90}{DiffBind} & \rotatebox{90}{DESeqIDR} & \rotatebox{90}{Poisson-THOR} & \rotatebox{90}{csaw} \\
    \hline
    THOR-HK &     &     &     &     &     &     &     &     \\
    THOR-TMM &     &     &     &     &     &     &     &     \\
    macs2 &     &     &     &     &     &     &     &     \\
    DiffReps &     &     &     &     &     &     &     &     \\
    DiffBind & $*$ & $+$ &     &     &     &     &     &     \\
    DESeqIDR & $*$ & $*$ &     &     &     &     &     &     \\
    Poisson-THOR & $*$ & $*$ &     &     &     &     &     &     \\
    csaw & $*$ & $*$ & $*$ &     &     &     &     &     \\
    \hline
  \end{tabular}
\end{center}
\caption[Friedman-Nemenyi test of DCA results]{Friedman-Nemenyi hypothesis test results for the DCA score ($h=500, H=10000$). The asterisk and the cross, respectively, mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1.}
\label{tab_res_real_with_rep_without_pepr_sig}
\end{table}

\noindent
As PePr requires input-DNA data and therefore cannot be executed for MM and CO, we repeat the Friedman-Nemenyi test on DCA values from DC and LYMP only.
In this case, THOR-HK has significantly higher DCA score than csaw ($p$-value$<$0.05) as well as Poisson-THOR ($p$-value$<$0.1, Sup. Table~\ref{tab_res_real_with_rep_with_pepr} -- Sup. Table~\ref{tab_res_real_with_rep_with_pepr_sig}) and THOR-TMM outperforms csaw ($p$-value$<$0.05). 
There is no significant differences for all other competing methods. 

As an example, we show in Figure~\ref{fig_overdispersion_thor}A DPs for H3K4me3 histone modification on the monocyte to ma\-cro\-phage differentiation (MM) experiments of genes discussed in the original study from~\cite{Stunnenberg2014}. 
DiffBind and DESeq-IDR do not call any DPs in this region. 
THOR calls a combination of gain (green) and decrease (red) in H3K4me3 levels in IRAK3's and PDK2's promoters. 
Csaw peaks misses regions with large histone changes in both cases. 
MACS2 only detects a small lost peak in IRAK3 promoter, while DiffReps detects rather large gain peaks in both promoters. 
The average peak size of all analyzed data supports the fact that DiffReps tends to call larger DPs (1893bps) and MACS2 smaller DPs (296bps) than all other tools (1133bps) (see Figure~\ref{fig_peak_size_distr}).

\begin{figure}[th]
  \begin{center}
%     \includegraphics[width=\textwidth]{pics/frip_overdisp_dpexample.pdf}
%     \includegraphics[width=\textwidth]{pics/frip_overdisp_dpexample.png}
  \end{center}
\caption[Example of DPs in biological data and DCA-overdispersion association]{Example of DPs estimates and DCA-overdispersion association. \textbf{(A)} We depict an overlay of all H3K4me3 and RNA-seq signals for monocytes (red) and macrophages (green) around the promoter of IRAK3 and PDK2 for THOR and competing methods. We show the 10,000 most significant DPs of each method. \textbf{(B)} Association between the difference of THOR DCA scores with the best competing method and the overdispersion score of 12 differential peak calling problems divided by gain and lost peaks.
\textbf{an Prof. Berlage: Ich habe bei den plots je zwei Versionen: das ChIP-seq Signal als lineplot wie hier und als barplot. Welche Version soll ich nehmen? (siehe Figure ~\ref{fig_results_without_rep_example_ext}, \ref{fig_gene_dp_DC}, \ref{fig_rsnps}, \ref{pic_ratio_to_noise}, \ref{pic_dp_example}, \ref{fig_intro})}}
\label{fig_overdispersion_thor}
\end{figure}
% XXX remove Berlage part


\begin{figure}[th]
  \begin{center}
    \includegraphics[width=9cm]{pics/Peak_Size_Var.pdf}
  \end{center}
\caption[Differential peak size distributions]{DP size distribution for each tool. 
The boxplot of each tool gives the DP size distribution obtained from predictions on all biological data.}
\label{fig_peak_size_distr}
\end{figure}

 
 
\subsubsection{Overdispersion Impact on Differential Peak Calling Performance}
As previously described, follicular lymphoma (LYMP) experiments exhibit highest overdispersion values, while the dendritic cell differentiation study has the lowest. 
Interestingly, the DCA scores supports the notion that THOR has relatively better performance than competing tools in data with high within condition variance such as LYMP-FL-CC (Figure~\ref{fig_res_real_datasets_with_rep}C), while it performs comparatively well with other competing methods such as in DC-CDP-cDC (Figure~\ref{fig_res_real_datasets_with_rep}B). 
To investigate this more systematically, we measured the difference between the THOR-HK vs. the best DCA for competing methods. 
As indicated in Figure~\ref{fig_overdispersion_thor}B, there is a moderate association between $\Delta$ DCA and the overdispersion score (R=0.36; adjusted $p$-value$<$0.1). 
The $\Delta$ DCA is large for experiments with high number of replicates and genetic variance between samples from MM and LYMP.  

Another important question is the performance of the two normalization approaches supported by THOR. 
While the Friedman rank indicates THOR-HK has overall better ranking, the difference in ranks between the TMM and HK approaches is not statistically significant. 
Considering the difference in DCA scores for THOR-HK and THOR-TMM (Figure~\ref{pic_delta_DCA_THOR}), we observe that both methods perform similarly in most data sets. 
However, THOR-HK clearly outperforms THOR-TMM in four conditions from LYMPH (LYMP-CC-PBBA gain, LYMP-CC-PBBA loss, LYMP-FL-CC loss and LYMP-FL-PBBA loss). 
These conditions have small FRiP ($<$ 0.05) and large overdispersion estimates ($>$ 0.03). 
These results indicate that in cases with high variance or low signal-to-noise ratio it is advisable to perform a housekeeping gene normalization strategy.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{pics/THOR_Norm_Overdispersion_Frip.pdf}
  \end{center}
  \caption[Association DCA THOR vs. FRiP and Overdispersion]{Association between the difference in DCA values for THOR normalization approaches (THOR-HK - THOR-TMM) vs. the average FRiP or overdispersion scores.}
  \label{pic_delta_DCA_THOR}
\end{figure}

\subsection{Use Cases of THOR}
We describe two use cases for THOR.
First, we apply THOR to the LYMP-FL-CC data set to evaluate the ability of THOR to call DPs that support rSNPs.
Second, we evaluate whether DPs called by THOR for the data sets DC-H3K27ac-CDP-cDC and DC-H3K27ac-CDP-pDC are associated to dendritic cell genes.

\subsubsection{Identifying rSNPs}
\label{res_ident_rsnps}
In this experiment we analyse THOR's ability to call DPs that support rSNPs.
For the data set LYMP-FL-CC (see Table~\ref{table_datasets_with_replicates}), we first call DPs with THOR and second use GATK to identify rSNPs.
Next, we filter SNPs that do not lie within DPs (see Sup. Table~\ref{tab_res_candidate_SNPs} for an selection).
In Section~\ref{sec_expmethod_rsnps}, we describe in detail how we obtain the 137 candidate rSNPs.

We apply GREAT~\citep{McLean2010} to perform an enrichment analysis of the 203 genes that are neighbouring the candidate rSNPs.
GREAT assigns biological meaning to non-coding genomic regions such as rSNPs.
For that, GREAT assigns the rSNPs to genes in the vicinity and details the biological function of the genes.
All resulting 27 enriched gene sets are associated to lymphoid cells, such as \textit{abnormal lymphocyte morphology} (adjusted $p$-value=$6.5 \cdot 10^{-4}$; 39 annotated genes) and \textit{abnormal B cell morphology} ($p$-value=0.0011; 23 annotated genes).
Concerning the 28 rSNPs detected in the original study \citep{Koues2015}, there is no overlap of our candidate rSNPs and the GREAT analysis indicates no enriched terms. 
However, note that \cite{Koues2015} employ a distinct strategy to detect rSNPs, which was based on comparing the reads of single FL patients vs. all CC cells.

Next, we select six genomic regions with seven rSNPs which are close to genes with "abnormal lymphocyte morphology" as indicated by GREAT, lie within a DP with low $p$-value ($< 10^{-14}$) and the rSNP disrupted (or enhanced) transcription factor binding sites (TFBS). 
One interesting cluster of rSNPs is present in the locus of the G-receptor gene family RGS. 
The second ranked (by lowest DP $p$-value) rSNP is located in the promoter of RGS2 (Figure~\ref{fig_rsnps}A) and two rSNPs (DP ranks 6 and 7) lie in an enhancer region between RGS1 and RGS13 (Figure~\ref{fig_rsnps}B). 
There are lower levels of H3K27ac around all rSNPs and in the promoters of these genes indicating a decrease of gene activity. 
We also find that rSNPs change binding affinity of TFBS of B-cell factors Bcl6 (disruption) and Ikaros (enhancement) as well as the repressive chromatin remodelling factor YY1 (enhancement). 
Genes in these loci (RGS1, RGS2 and RGS13) have been previously reported to  be associated to B cell motility~\citep{Han2005} and to regulation of germinal center B cells~\citep{Shi2002}.

\begin{figure}[h]
\begin{center}
%   \includegraphics[width=\textwidth]{pics/rsnps.pdf}
%   \includegraphics[width=\textwidth]{pics/rsnps.png}
\end{center}
\caption[Selection of regulatory SNPs]{Selection of regulatory SNPs. We depict FL (red signal) and CC (green signal) located in DPs called by THOR (red/green bars under ChIP-seq signals). For each rSNP, we indicate close genes and a table with the frequency of the common (top) and alternative (bottom) alleles. We also show examples of TFBS motifs being disrupted by the rSNPs. Red (black) boxes indicate the motif position that is disrupted (enhanced).}
\label{fig_rsnps}
\end{figure}

\noindent
The rSNPs in DP rank 5 is in the vicinity of IL-18BP (Figure~\ref{fig_rsnps}C). 
Both rSNP region and IL-18BP have increased H3K27ac levels in FL patients. 
Interestingly, the rSNP disrupt a Ikaros binding site. 
IL-18BP is known to antagonize the IL-18 receptor and Interferon responses in immune cells~\citep{Yoshimoto1998}. 
Another interesting rSNP locus (rank 10) is close to NEAT1 (and MALAT1) (Figure~\ref{fig_rsnps}D). 
This genomic region displays high losses of H3K27ac on FL condition. 
Among others, we find disruption of motifs of the Meis1 factor. 
While MALAT1 and NEAT1 have not been associated to B cell lymphomas, these long non-coding genes have prominent functions in RNA splicing and cancer~\citep{Gutschner2013}.
Moreover, a rSNP (rank 13, Figure~\ref{fig_rsnps}E) is in the vicinity of the kinase PTK2B, which has increased H327ac levels in FL patients. 
The rSNP enhanced the binding of the hematopoietic master regulated Sfp1. 
This kinase has been shown to be relevant for marginal zone B cells in mice~\citep{Guinamard2000}.

Finally, rSNP on rank 19 (Figure~\ref{fig_rsnps}F) lies in a intergenic region of gene CCR6 and disrupts the binding of a Klf4 factor. 
CC chemokines are known regulators of both B cell as well as cancer cell migration and were also among the genes found in the original study~\citep{Koues2015}.  
Altogether, these results indicate the power of THOR by detecting DPs supporting rSNPs. 

% \subsection{Leukemia Study}
% \subsubsection{Background and Motivation}
% \begin{itemize}
%  \item describe leukemia as cancer, go into details about different types of leukemia: chronic myelogenous leukemia (CML) polycythemia vera (PV)
%  \item describe drug that is used for treatment
%  \item CML: chromosome translocation; PV: SNP on JAK2 gene
%  \item aim of this study: epigenetic differences between CMl and PV
% \end{itemize}
% 
% \subsubsection{Data}
% \begin{itemize}
%  \item describe data that are available: 2 technical replicates for CML and PV of healthy and diseased tissue, diseased tissue is either treated or not treated with particular drug
%  \item ChIP-seq experiments: histone modification H3K9ac with input-DNA
%  \item mouse and human tissue
%  \item give quality metric table: one dataset is negatively sticking out: we ignore it and take another healthy tissue sample into account
% \end{itemize}
% 
% \subsubsection{Differential Peak Analysis}
% \begin{itemize}
%  \item we use THOR and compare threated vs. non-treated tissue for both kinds of leukemia, separated for mouse and human
%  \item associate differential peaks with gene expression
%  \item take transcription factor analysis into account
%  \item give candidate genes that are up/down regulated in treated vs. non-treated tissue
%  \item H3K9ac is potentially an important regulatory mechanism for leukemia
% \end{itemize}

\subsubsection{Dendritic Cell Development Analysis}
We evaluate if DPs are close to genes which are relevant for dendritic cell differentiation. 
Here, we only evaluate genes gained in cDC (compared to CDP) and pDC (compared to CDP) using H3K27ac (see data set DC-H3K27ac-CDP-cDC/pDC in Table~\ref{table_datasets_with_replicates}).

First, we perform an analysis with GREAT to evaluate the biological functions associated to genes. 
For cDC peaks, we obtain \textit{MHC class II protein complex} (adjusted $p$-value=$1.8 \cdot 10^{-106}$; 8 annotated genes) and \textit{antigen processing and presentation of exogenous peptide antigen via MHC class II} (adjusted $p$-value=$1.1 \cdot 10^{-76}$; 6 annotated genes).
The major histocompatibility complex (MHC) class II is a molecule family that occurs in antigen presenting cells such as dendritic cells~\citep{Ting2002}.
For pDC peaks, the GREAT analysis yields \textit{interferon receptor activity} (adjusted $p$-value=$5.5 \cdot 10^{-41}$; one annotated gene) and \textit{type~I interferon production} (adjusted $p$-value=$6.1 \cdot 10^{-39}$; one annotated gene).
Interferons are a protein family in the response against viruses and cancer cells, which are known functions of dendritic cells~\citep{DeAndrea2002}.

Second, we evaluate DPs by assigning them to genes in their vicinity. 
Sup. Table~\ref{tab_res_dc_cDC_gene_list} gives the top 50 ranked genes that are close to DPs gained in cDC cells.
ID2 (rank 4) is a important factor associated to cDC differentiation, and is known to have low expression in the precursors cell CDP ~\citep{Jackson2011}.
Also, receptor genes ADAM19 (rank 13) and KIT (rank 47) are known markers of cDC cells~\citep{Miller2012}.
Six of the top eight ranked genes, that is, H2-AA, H2-AB1, H2EB-1, H2-EA-PS, H2-EB2 (see Figure~\ref{fig_gene_dp_DC}C) and CD74 (see Figure~\ref{fig_gene_dp_DC}D), as well as several further other listed genes (H2-DMB1 (rank 16), H2-DMB2 (rank 17), CIITA (rank 28) and H2-OB (rank 37)) code proteins that are part of the MHC class II family.
Moreover, gene IRF8 (rank 14) regulates distinct stages of the DC differentiation~\citep{Jackson2011}.
 
Sup. Table~\ref{tab_res_dc_pDC_gene_list} lists the top 50 genes close to pDC gain peaks. 
The top ranked gene SIGLECH (see Figure~\ref{fig_gene_dp_DC}A) is a receptor widely used as pDC identification marker~\citep{Zhang2006}.
Moreover, gene IRF8 (rank 2, see Figure~\ref{fig_gene_dp_DC}B), gene TCF4 (rank 41) and gene RUNX2 (rank 49) play key roles in the development of pDC cells~\citep{Jaiswal2013, Cisse2008, Sawai2013}.
Gene PACSIN1 (rank 36) regulates the interferon response specifically in pDC cells.
Gene IFNAR1 (rank 9) and IL10RB (rank 10) code interferon receptors.
Altogether, THOR identifies several genes that are associated with either cDC or pDC cells. 
This indicates that THOR's results go in accordance with prior biological knowledge.

\begin{figure}[ht]
\begin{center}
%   \includegraphics[width=\textwidth]{pics/example_thor_use_case_DC.pdf}
%   \includegraphics[width=\textwidth]{pics/example_thor_use_case_DC.png}
\end{center}
\caption[Genes with most significant DPs.]{Genes with most significant DPs.
We give examples of genes that are associated to the most significant DPs for histone modification H3K27ac with two replicates.
For the data set DC-H3K4ac-CDP-pDC (top) we show genes SIGLECH (A) and IRF8 (B), and for data set DC-H3K4ac-CDP-pDC (bottom) we picture gene CD74 (C) and genes that code of the MHC class~II family (D).}
\label{fig_gene_dp_DC}
\end{figure}
